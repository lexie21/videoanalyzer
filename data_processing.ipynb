{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>language</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>channel</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>tag_num</th>\n",
       "      <th>title_len</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>short_vid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The complete FUN TO IMAGINE with Richard Feynman</td>\n",
       "      <td>4165520</td>\n",
       "      <td>87497</td>\n",
       "      <td>7292</td>\n",
       "      <td>2018-11-01T13:22:07Z</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>en-US</td>\n",
       "      <td>You can find an HD upload at https://youtu.be/...</td>\n",
       "      <td>['feynman', 'science', 'physics', 'history', '...</td>\n",
       "      <td>Christopher Sykes</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>13:22:07</td>\n",
       "      <td>2018</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's no such thing as MIRACLE, Richard Feyn...</td>\n",
       "      <td>3894360</td>\n",
       "      <td>145637</td>\n",
       "      <td>2841</td>\n",
       "      <td>2020-08-26T20:21:49Z</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this video, Richard Feynman talks about why...</td>\n",
       "      <td>['study with me', 'study', 'music for studying...</td>\n",
       "      <td>BTY 365</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>20:21:49</td>\n",
       "      <td>2020</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard Feynman talks about Algebra</td>\n",
       "      <td>1383026</td>\n",
       "      <td>28242</td>\n",
       "      <td>1592</td>\n",
       "      <td>2014-01-22T19:33:22Z</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From the Pleasure of Finding Things Out. I lov...</td>\n",
       "      <td>['Richard Feynman (Author)', 'Algebra (Mathema...</td>\n",
       "      <td>David Petro</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>19:33:22</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inside the Mind of Richard Feynman: The Great ...</td>\n",
       "      <td>1295632</td>\n",
       "      <td>40328</td>\n",
       "      <td>2102</td>\n",
       "      <td>2013-03-04T20:01:32Z</td>\n",
       "      <td>624.0</td>\n",
       "      <td>en</td>\n",
       "      <td>In today's SciShow episode of Great Minds, we'...</td>\n",
       "      <td>['richard feynman', 'quantum electrodynamics',...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>2013-03-04</td>\n",
       "      <td>20:01:32</td>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best teacher I never had</td>\n",
       "      <td>4618209</td>\n",
       "      <td>170957</td>\n",
       "      <td>2872</td>\n",
       "      <td>2016-01-27T16:01:46Z</td>\n",
       "      <td>156.0</td>\n",
       "      <td>en</td>\n",
       "      <td>A video tribute from Bill Gates to Richard Fey...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>16:01:46</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  view_count  like_count  \\\n",
       "0   The complete FUN TO IMAGINE with Richard Feynman     4165520       87497   \n",
       "1  There's no such thing as MIRACLE, Richard Feyn...     3894360      145637   \n",
       "2                Richard Feynman talks about Algebra     1383026       28242   \n",
       "3  Inside the Mind of Richard Feynman: The Great ...     1295632       40328   \n",
       "4                       The best teacher I never had     4618209      170957   \n",
       "\n",
       "   comment_count          publish_time  duration language  \\\n",
       "0           7292  2018-11-01T13:22:07Z    4010.0    en-US   \n",
       "1           2841  2020-08-26T20:21:49Z     320.0      NaN   \n",
       "2           1592  2014-01-22T19:33:22Z      82.0      NaN   \n",
       "3           2102  2013-03-04T20:01:32Z     624.0       en   \n",
       "4           2872  2016-01-27T16:01:46Z     156.0       en   \n",
       "\n",
       "                                         description  \\\n",
       "0  You can find an HD upload at https://youtu.be/...   \n",
       "1  In this video, Richard Feynman talks about why...   \n",
       "2  From the Pleasure of Finding Things Out. I lov...   \n",
       "3  In today's SciShow episode of Great Minds, we'...   \n",
       "4  A video tribute from Bill Gates to Richard Fey...   \n",
       "\n",
       "                                                tags            channel  \\\n",
       "0  ['feynman', 'science', 'physics', 'history', '...  Christopher Sykes   \n",
       "1  ['study with me', 'study', 'music for studying...            BTY 365   \n",
       "2  ['Richard Feynman (Author)', 'Algebra (Mathema...        David Petro   \n",
       "3  ['richard feynman', 'quantum electrodynamics',...            SciShow   \n",
       "4                                                 []         Bill Gates   \n",
       "\n",
       "         date      time  year  tag_num  title_len  desc_len  short_vid  \n",
       "0  2018-11-01  13:22:07  2018       36          8        98          0  \n",
       "1  2020-08-26  20:21:49  2020       18         14        79          0  \n",
       "2  2014-01-22  19:33:22  2014        3          5        33          0  \n",
       "3  2013-03-04  20:01:32  2013       25          9       113          0  \n",
       "4  2016-01-27  16:01:46  2016        2          6        21          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_data.csv')\n",
    "df.drop(df.columns[0],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "#### Our final goal is to use Multiple Linear Regression to predict the view counts for a RPF-related video. But in order to do that, first we need to transform our text data into numerical values before feeding them into the model. We will use sklearn text frequency - inverse document frequency model for this task. There are 2 main steps that we need to go through in this processing stage. First, we'll go through them one by one and then, we'll build a pipeline to automate.\n",
    "\n",
    "* Text Pre-processing: using the simple bag-of-words approach, where each unique word in a text is represented by one number\n",
    "* Vectorization: we'll convert the list of tokens above into a vector that machine learning models can understand.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Text Pre-processing\n",
    "The text features for this section include\n",
    "* Titles\n",
    "* Description\n",
    "* Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a function that takes 2 features - title, description - and outputs their respective bag-of-words because these need more preprocessing than tags? Actually no, still need to remove punctuation and stopwords.\n",
    "\n",
    "TODO: stopwords of other languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    1. remove punctuation\n",
    "    2. remove stopwords, numbers\n",
    "    '''\n",
    "    if type(text) == str:\n",
    "        no_punc = [char for char in text if char not in string.punctuation]\n",
    "        no_punc = ''.join(no_punc)\n",
    "    return [word for word in no_punc.split() if (word.lower() not in stopwords.words('english')) and (not word.isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [feynman, science, physics, history, philosoph...\n",
       "1    [study, study, music, studying, focus, music, ...\n",
       "2    [Richard, Feynman, Author, Algebra, Mathematic...\n",
       "3    [richard, feynman, quantum, electrodynamics, c...\n",
       "4                                                   []\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try applying this\n",
    "df['tags'].head(5).apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Vectorization ... explain clearly what needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need to create func here, later with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try this on tags first\n",
    "bow_transformer = CountVectorizer(analyzer=tokenize).fit(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2716"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10Cosas', '3K', '3blue1brown', '4K', '4k', '9LX', 'ACME', 'AI',\n",
       "       'APhDDoesntMakeYouIntelligent', 'Academic', 'Academy',\n",
       "       'Accommodation', 'Admission', 'Advice', 'Affirmation', 'Age',\n",
       "       'Alamos', 'Albert', 'Albuquerque', 'Algebra', 'Alt', 'Altyazı',\n",
       "       'Altyazılı', 'Amazing', 'America', 'American', 'Another',\n",
       "       'AntiOtário', 'Approach', 'Aprenda'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names_out()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = bow_transformer.transform(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 1 item\n",
    "bow_3 = bow_transformer.transform([df['tags'][3]])\n",
    "bow_transformer.get_feature_names_out()[1641]\n",
    "'explainer' in df['tags'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jewish'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names_out()[1641]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 2716)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 233)\t1\n",
      "  (0, 254)\t2\n",
      "  (0, 296)\t1\n",
      "  (0, 298)\t2\n",
      "  (0, 302)\t2\n",
      "  (0, 343)\t1\n",
      "  (0, 477)\t1\n",
      "  (0, 627)\t1\n",
      "  (0, 657)\t2\n",
      "  (0, 825)\t1\n",
      "  (0, 1131)\t1\n",
      "  (0, 1133)\t1\n",
      "  (0, 1233)\t1\n",
      "  (0, 1305)\t2\n",
      "  (0, 1399)\t3\n",
      "  (0, 1505)\t1\n",
      "  (0, 1640)\t1\n",
      "  (0, 1641)\t3\n",
      "  (0, 1725)\t1\n",
      "  (0, 1777)\t1\n",
      "  (0, 1793)\t1\n",
      "  (0, 1796)\t1\n",
      "  (0, 1799)\t1\n",
      "  (0, 1835)\t1\n",
      "  (0, 1913)\t1\n",
      "  (0, 1941)\t2\n",
      "  (0, 2006)\t1\n",
      "  (0, 2020)\t1\n",
      "  (0, 2042)\t1\n",
      "  (0, 2051)\t1\n",
      "  (0, 2094)\t2\n",
      "  (0, 2107)\t1\n",
      "  (0, 2138)\t4\n",
      "  (0, 2210)\t3\n",
      "  (0, 2250)\t1\n",
      "  (0, 2266)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6497"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_bow.toarray()\n",
    "df_bow.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46812539448769197"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate sparsity\n",
    "sparsity = (100*df_bow.nnz/(df_bow.shape[0]*df_bow.shape[1]))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighing and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(df_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = tfidf_transformer.transform(df_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 2716)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2587)\t0.17031115887164838\n",
      "  (0, 2535)\t0.1383383351514275\n",
      "  (0, 2399)\t0.16381703032050798\n",
      "  (0, 2253)\t0.08002395274413629\n",
      "  (0, 2215)\t0.19048376466243103\n",
      "  (0, 2163)\t0.19048376466243103\n",
      "  (0, 2128)\t0.17868354673299272\n",
      "  (0, 2051)\t0.0743926877109857\n",
      "  (0, 2044)\t0.12653811722198924\n",
      "  (0, 1982)\t0.19048376466243103\n",
      "  (0, 1941)\t0.11697769018780234\n",
      "  (0, 1839)\t0.17868354673299272\n",
      "  (0, 1827)\t0.19048376466243103\n",
      "  (0, 1792)\t0.12205188257551142\n",
      "  (0, 1765)\t0.19048376466243103\n",
      "  (0, 1764)\t0.19048376466243103\n",
      "  (0, 1726)\t0.1540247062957323\n",
      "  (0, 1707)\t0.19048376466243103\n",
      "  (0, 1694)\t0.11697769018780234\n",
      "  (0, 1577)\t0.15013855308086577\n",
      "  (0, 1548)\t0.17868354673299272\n",
      "  (0, 1543)\t0.15013855308086577\n",
      "  (0, 1532)\t0.16381703032050798\n",
      "  (0, 1456)\t0.14364442452972534\n",
      "  (0, 1419)\t0.15013855308086577\n",
      "  :\t:\n",
      "  (508, 2572)\t0.09544051298999208\n",
      "  (508, 2461)\t0.09544051298999208\n",
      "  (508, 2309)\t0.17066634943335982\n",
      "  (508, 2308)\t0.09544051298999208\n",
      "  (508, 2020)\t0.08533317471667991\n",
      "  (508, 1584)\t0.4772025649499604\n",
      "  (508, 1295)\t0.25599952415003974\n",
      "  (508, 1120)\t0.4772025649499604\n",
      "  (508, 1119)\t0.5726430779399525\n",
      "  (508, 970)\t0.17066634943335982\n",
      "  (508, 955)\t0.08207933856197039\n",
      "  (508, 903)\t0.19088102597998416\n",
      "  (510, 1203)\t0.29463796020355637\n",
      "  (510, 795)\t0.2834031309517062\n",
      "  (510, 716)\t0.3295365274000014\n",
      "  (510, 646)\t0.2742236070647386\n",
      "  (510, 627)\t0.10439850291526824\n",
      "  (510, 506)\t0.2742236070647386\n",
      "  (510, 307)\t0.3295365274000014\n",
      "  (510, 254)\t0.10079076791466013\n",
      "  (510, 207)\t0.29463796020355637\n",
      "  (510, 101)\t0.2742236070647386\n",
      "  (510, 44)\t0.29463796020355637\n",
      "  (510, 43)\t0.3295365274000014\n",
      "  (510, 17)\t0.29463796020355637\n"
     ]
    }
   ],
   "source": [
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1641"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can grab the col of each unique word via bow_transformer.vocabulary_\n",
    "# Then we can get the idf of each word with the fitted tfidf.idf_ \n",
    "# get_feature_name_out() = inverse of vocabulary_\n",
    "\n",
    "bow_transformer.vocabulary_['jewish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.041100047703289"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['caltech']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.465735902799727"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['electrodynamics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2716"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_transformer.idf_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done preprocessing the text for input. Now let's pass that to the MLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try on the processed tags input first\n",
    "\n",
    "view_predict_model = LinearRegression().fit(df_tfidf,df['view_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3894353.48546109])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_predict_model.predict(df_tfidf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_view = view_predict_model.predict(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3894360"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1][1] # pretty close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607831528143813"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 score\n",
    "r2_score(df['view_count'],predicted_view) # pretty high, but train and test on the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try on the processed tags input first\n",
    "\n",
    "tag_train, tag_test, label_train, label_test = train_test_split(df['tags'],df['view_count'],test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=tokenize)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('regressor',LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42     ['Richard', 'Feynman', 'Messenger', 'Lectures'...\n",
       "58     ['Richard', 'Feynman', 'understanding', 'physi...\n",
       "455               ['Ciencias', 'TV', 'Facultad', 'UNAM']\n",
       "78                                                    []\n",
       "484                                                   []\n",
       "                             ...                        \n",
       "255    ['RichardFeynman', 'PhysicsGenius', 'NobelPriz...\n",
       "72     ['ciencia', 'richard feynman', 'ciencia difici...\n",
       "396    ['Richard Feynman', 'Interpretation', 'quantum...\n",
       "235                                                   []\n",
       "37     ['richard feynman', 'enrico fermi', 'robert op...\n",
       "Name: tags, Length: 408, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                 CountVectorizer(analyzer=&lt;function tokenize at 0x0000020D18650C20&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;regressor&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                 CountVectorizer(analyzer=&lt;function tokenize at 0x0000020D18650C20&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;regressor&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&lt;function tokenize at 0x0000020D18650C20&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function tokenize at 0x0000020D18650C20>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('regressor', LinearRegression())])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(tag_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3440153761832492"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(tag_test,label_test) #this calculate R2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(tag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293313007511.9368"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the MSE ourselves\n",
    "\n",
    "np.mean((predictions-label_test)**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47      70133.369267\n",
       "345    -37600.630733\n",
       "284   -493349.712538\n",
       "221    524972.338025\n",
       "502    -37135.630733\n",
       "           ...      \n",
       "92     182237.541372\n",
       "225    -42119.630733\n",
       "411   -628264.006722\n",
       "329         1.142551\n",
       "446    -45130.630733\n",
       "Name: view_count, Length: 103, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1293313007511.9368\n",
      "Mean Squared Error: 1293313007511.9368\n",
      "R2: -0.3440153761832492\n"
     ]
    }
   ],
   "source": [
    "mae = mean_squared_error(label_test,predictions)\n",
    "mse = mean_squared_error(label_test,predictions)\n",
    "r2 = r2_score(label_test,predictions)\n",
    "print('Mean Absolute Error:',mae)\n",
    "print('Mean Squared Error:',mse)\n",
    "print('R2:',r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative R-squared means the model is worse in predicting variation in the data than its mean value. What did we do wrong?\n",
    "Several reasons for this:\n",
    "* No relation between tag content and view_counts (could be, since normally we only look at titles to determine whether to watch something or not)\n",
    "* Something wrong with our tokenization method (guess = compound phrases without space were skipped)\n",
    "* Better pass this in as a regressor in a multiple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to tokenize tags more thoroughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5779314264900488"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with titles\n",
    "\n",
    "title_train, title_test, view_train, view_test = train_test_split(df['title'],df['view_count'],test_size=0.2,random_state=1)\n",
    "pipeline.fit(title_train,view_train).score(title_test,view_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518404681229.7773"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipeline.predict(title_test)\n",
    "np.mean((predictions-view_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1518404681229.7773\n",
      "Mean Squared Error: 1518404681229.7773\n",
      "R2: -0.5779314264900488\n"
     ]
    }
   ],
   "source": [
    "mae = mean_squared_error(view_test,predictions)\n",
    "mse = mean_squared_error(view_test,predictions)\n",
    "r2 = r2_score(view_test,predictions)\n",
    "print('Mean Absolute Error:',mae)\n",
    "print('Mean Squared Error:',mse)\n",
    "print('R2:',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -57566.87984615,  559312.23004949,  550980.23866265, ...,\n",
       "       -213894.98038508, -213894.98038508,  -13263.37352132])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.named_steps['regressor'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no apparent relationship between the text input and view_counts, let's only use the other originally numeric variables in our MLR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create to_current as years from publishing year to current year\n",
    "from datetime import datetime\n",
    "df['to_current'] = datetime.now().year - df['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[['like_count','comment_count','duration','to_current','tag_num','title_len','desc_len','short_vid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>to_current</th>\n",
       "      <th>tag_num</th>\n",
       "      <th>title_len</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>short_vid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87497</td>\n",
       "      <td>7292</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145637</td>\n",
       "      <td>2841</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28242</td>\n",
       "      <td>1592</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40328</td>\n",
       "      <td>2102</td>\n",
       "      <td>624.0</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170957</td>\n",
       "      <td>2872</td>\n",
       "      <td>156.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   like_count  comment_count  duration  to_current  tag_num  title_len  \\\n",
       "0       87497           7292    4010.0           5       36          8   \n",
       "1      145637           2841     320.0           3       18         14   \n",
       "2       28242           1592      82.0           9        3          5   \n",
       "3       40328           2102     624.0          10       25          9   \n",
       "4      170957           2872     156.0           7        2          6   \n",
       "\n",
       "   desc_len  short_vid  \n",
       "0        98          0  \n",
       "1        79          0  \n",
       "2        33          0  \n",
       "3       113          0  \n",
       "4        21          0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((459, 8), (52, 8))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sub_df,df['view_count'],test_size=0.1,random_state=1)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6245182945891695"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rige = Ridge().fit(x_train,y_train).score(x_test,y_test)\n",
    "rige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6245130375083291"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().fit(x_train,y_train).score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_df2 = df[['like_count','duration','to_current','tag_num','title_len','desc_len','short_vid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: standard scaling input data\n",
    "\n",
    "examine how to incorporate the text input matrix as one regressor among other numeric variables.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
